{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4329353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 11:08:33.480579: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import tiktoken\n",
    "from src.model import GPTModel, replace_linear_with_lora\n",
    "from src.finetune import train_model_simple, generate_text_simple, text_to_token_ids, token_ids_to_text, generate\n",
    "from src.formatter import format_input_advanced\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from src.loader import load_weights_into_gpt, download_and_load_gpt2\n",
    "from src.finetune import calc_loss_loader, train_model_simple, train_model_with_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c634be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 52002\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib.request\n",
    "import ssl\n",
    "import certifi\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        # Create verified SSL context\n",
    "        ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    \n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"../data/alpaca-instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json\"\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b457f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Give three tips for staying healthy.', 'input': '', 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee631af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_STYLE = 'enhanced'\n",
    "\n",
    "def format_input(entry):\n",
    "    \"\"\"\n",
    "    Format instruction using the advanced formatter module.\n",
    "    \n",
    "    Available styles:\n",
    "    - 'enhanced': Improved Alpaca format (recommended)\n",
    "    - 'chatml': ChatML-style format (ChatGPT/GPT-4 style)\n",
    "    - 'task_aware': Adapts based on task type\n",
    "    - 'cot': Chain-of-thought for reasoning tasks\n",
    "    - 'structured': Encourages structured outputs\n",
    "    \"\"\"\n",
    "    return format_input_advanced(entry, style=PROMPT_STYLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf0a6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 44201\n",
      "Validation set length: 2601\n",
      "Test set length: 5200\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)    #1\n",
    "test_portion = int(len(data) * 0.1)            #2\n",
    "val_portion = len(data) - train_portion - test_portion    #3\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd90c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:         #1\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d423618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92472649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    \"\"\"Original collate function (kept for comparison)\"\"\"\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        \n",
    "        padded = (                               \n",
    "            new_item + [pad_token_id] *          \n",
    "            (batch_max_length - len(new_item))   \n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])      \n",
    "        targets = torch.tensor(padded[1:])     \n",
    "\n",
    "        mask = targets == pad_token_id              \n",
    "        indices = torch.nonzero(mask).squeeze()     \n",
    "        if indices.numel() > 1:                     \n",
    "            targets[indices[1:]] = ignore_index     \n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]       \n",
    "            targets = targets[:allowed_max_length]     \n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18d2542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# if torch.backends.mps.is_available():   #1\n",
    "#     device = torch.device(\"mps\")\"      \n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc16fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Option 1: Use original collate function (compatible with existing code)\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,  # Changed from custom_collate_fn_optimized\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5cf6197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0      #1\n",
    "batch_size = 4\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c072f82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Batch size: 4\n",
      "Total samples: 44201\n",
      "Samples per epoch: 44201\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "# Complete information about your DataLoader\n",
    "print(f\"Batch size: {train_loader.batch_size}\")\n",
    "print(f\"Total samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Samples per epoch: {len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b14225",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-large (774M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,          #1\n",
    "    \"context_length\": 1024,       #2\n",
    "    \"drop_rate\": 0.1,             #3\n",
    "    \"qkv_bias\": True              #4\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c93489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Checkpoint not found: gpt2-large774M-sft3.pth\n",
      "Loading base GPT-2 model and applying LoRA...\n",
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n",
      "✓ Base model loaded with LoRA applied!\n",
      "Total trainable LoRA parameters: 7,047,816\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if checkpoint file exists\n",
    "checkpoint_path = \"gpt2-large774M-sft3.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"✓ Found existing checkpoint: {checkpoint_path}\")\n",
    "    print(\"Loading model from checkpoint with LoRA...\")\n",
    "    \n",
    "    # IMPORTANT: The checkpoint was saved from a LoRA-enabled model\n",
    "    # So we need to create a model WITH LoRA structure first\n",
    "    \n",
    "    # Step 1: Create a base model\n",
    "    model = GPTModel(BASE_CONFIG)\n",
    "    \n",
    "    # Step 2: Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Step 3: Apply LoRA (MUST match the rank/alpha used during training!)\n",
    "    # The checkpoint was saved with rank=16, alpha=16\n",
    "    replace_linear_with_lora(model, rank=8, alpha=16)\n",
    "    \n",
    "    # Step 4: NOW load the checkpoint (which includes LoRA weights)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint)\n",
    "    \n",
    "    # Step 5: Move to device and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"✓ Model loaded successfully from checkpoint!\")\n",
    "    print(f\"Total trainable LoRA parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"✗ Checkpoint not found: {checkpoint_path}\")\n",
    "    print(\"Loading base GPT-2 model and applying LoRA...\")\n",
    "    \n",
    "    # Download and load base GPT-2 model\n",
    "    model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "    settings, params = download_and_load_gpt2(\n",
    "        model_size=model_size, models_dir=\"gpt2\"\n",
    "    )\n",
    "    \n",
    "    # Create model and load pretrained weights\n",
    "    model = GPTModel(BASE_CONFIG)\n",
    "    load_weights_into_gpt(model, params)\n",
    "    model.eval()\n",
    "    \n",
    "    # Freeze base model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Apply LoRA for fine-tuning\n",
    "    replace_linear_with_lora(model, rank=8, alpha=16)\n",
    "    \n",
    "    # Move to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(\"✓ Base model loaded with LoRA applied!\")\n",
    "    print(f\"Total trainable LoRA parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f2cf414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves us forward.\n",
      "\n",
      "\"We are not going to be satisfied until we have a team that is competitive in every game.\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(INPUT_PROMPT, tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c890a3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.1452971935272216\n",
      "Validation loss: 3.3175879955291747\n",
      "Test loss: 3.488521766662598\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device, num_batches=5\n",
    "    )\n",
    "    test_loss = calc_loss_loader(\n",
    "        test_loader, model, device, num_batches=5\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06d1ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 1280)\n",
      "  (pos_emb): Embedding(1024, 1280)\n",
      "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (12): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (13): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (14): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (15): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (16): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (17): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (18): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (19): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (20): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (21): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (22): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (23): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (24): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (25): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (26): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (27): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (28): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (29): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (30): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (31): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (32): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (33): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (34): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (35): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=1280, out_features=50257, bias=False)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a058e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-resume: using latest checkpoint checkpoints/oom_step10299.pt\n",
      "Resuming from checkpoint: epoch 1, step 10299, batch 10303, tokens 6904832\n",
      "Starting training: epochs 1 to 3, eval every 5 steps\n",
      "Ep 1 (Step 010300): Train loss 1.151, Val loss 1.559\n",
      "Ep 1 (Step 010305): Train loss 1.416, Val loss 1.557\n",
      "Ep 1 (Step 010310): Train loss 1.275, Val loss 1.559\n",
      "Ep 1 (Step 010315): Train loss 1.174, Val loss 1.558\n",
      "Ep 1 (Step 010320): Train loss 1.092, Val loss 1.555\n",
      "Ep 1 (Step 010325): Train loss 1.261, Val loss 1.552\n",
      "Ep 1 (Step 010330): Train loss 1.315, Val loss 1.552\n",
      "Ep 1 (Step 010335): Train loss 1.234, Val loss 1.553\n",
      "Ep 1 (Step 010340): Train loss 1.243, Val loss 1.555\n",
      "Ep 1 (Step 010345): Train loss 1.170, Val loss 1.554\n",
      "Ep 1 (Step 010350): Train loss 1.216, Val loss 1.554\n",
      "Ep 1 (Step 010355): Train loss 1.119, Val loss 1.556\n",
      "Ep 1 (Step 010360): Train loss 1.245, Val loss 1.557\n",
      "Ep 1 (Step 010365): Train loss 1.226, Val loss 1.557\n",
      "Ep 1 (Step 010370): Train loss 1.162, Val loss 1.559\n",
      "Ep 1 (Step 010375): Train loss 1.248, Val loss 1.558\n",
      "Ep 1 (Step 010380): Train loss 1.346, Val loss 1.557\n",
      "Ep 1 (Step 010385): Train loss 1.156, Val loss 1.556\n",
      "Ep 1 (Step 010390): Train loss 1.425, Val loss 1.555\n",
      "Ep 1 (Step 010395): Train loss 1.167, Val loss 1.554\n",
      "Ep 1 (Step 010400): Train loss 1.304, Val loss 1.552\n",
      "Ep 1 (Step 010405): Train loss 1.255, Val loss 1.556\n",
      "Ep 1 (Step 010410): Train loss 1.054, Val loss 1.556\n",
      "Ep 1 (Step 010415): Train loss 1.096, Val loss 1.554\n",
      "Ep 1 (Step 010420): Train loss 1.305, Val loss 1.554\n",
      "Ep 1 (Step 010425): Train loss 0.909, Val loss 1.555\n",
      "Ep 1 (Step 010430): Train loss 1.241, Val loss 1.554\n",
      "Ep 1 (Step 010435): Train loss 1.145, Val loss 1.554\n",
      "Ep 1 (Step 010440): Train loss 1.098, Val loss 1.554\n",
      "Ep 1 (Step 010445): Train loss 1.373, Val loss 1.550\n",
      "Ep 1 (Step 010450): Train loss 1.347, Val loss 1.548\n",
      "Ep 1 (Step 010455): Train loss 1.256, Val loss 1.549\n",
      "Ep 1 (Step 010460): Train loss 1.269, Val loss 1.550\n",
      "Ep 1 (Step 010465): Train loss 1.098, Val loss 1.549\n",
      "Ep 1 (Step 010470): Train loss 1.040, Val loss 1.547\n",
      "Ep 1 (Step 010475): Train loss 1.317, Val loss 1.546\n",
      "Ep 1 (Step 010480): Train loss 1.396, Val loss 1.547\n",
      "Ep 1 (Step 010485): Train loss 1.338, Val loss 1.550\n",
      "Ep 1 (Step 010490): Train loss 1.106, Val loss 1.551\n",
      "Ep 1 (Step 010495): Train loss 1.200, Val loss 1.551\n",
      "Ep 1 (Step 010500): Train loss 1.192, Val loss 1.552\n",
      "Ep 1 (Step 010505): Train loss 1.133, Val loss 1.554\n",
      "Ep 1 (Step 010510): Train loss 1.315, Val loss 1.555\n",
      "Ep 1 (Step 010515): Train loss 1.216, Val loss 1.553\n",
      "Ep 1 (Step 010520): Train loss 1.030, Val loss 1.552\n",
      "Ep 1 (Step 010525): Train loss 1.287, Val loss 1.551\n",
      "Ep 1 (Step 010530): Train loss 1.418, Val loss 1.552\n",
      "Ep 1 (Step 010535): Train loss 1.026, Val loss 1.552\n",
      "Ep 1 (Step 010540): Train loss 1.237, Val loss 1.552\n",
      "Ep 1 (Step 010545): Train loss 1.250, Val loss 1.549\n",
      "Ep 1 (Step 010550): Train loss 1.347, Val loss 1.549\n",
      "Ep 1 (Step 010555): Train loss 1.227, Val loss 1.551\n",
      "Ep 1 (Step 010560): Train loss 1.088, Val loss 1.551\n",
      "Ep 1 (Step 010565): Train loss 1.205, Val loss 1.552\n",
      "Ep 1 (Step 010570): Train loss 1.347, Val loss 1.553\n",
      "Ep 1 (Step 010575): Train loss 1.415, Val loss 1.554\n",
      "Ep 1 (Step 010580): Train loss 1.206, Val loss 1.554\n",
      "Ep 1 (Step 010585): Train loss 1.273, Val loss 1.553\n",
      "Ep 1 (Step 010590): Train loss 1.258, Val loss 1.551\n",
      "Ep 1 (Step 010595): Train loss 1.211, Val loss 1.547\n",
      "Ep 1 (Step 010600): Train loss 1.171, Val loss 1.546\n",
      "Ep 1 (Step 010605): Train loss 1.311, Val loss 1.546\n",
      "Ep 1 (Step 010610): Train loss 1.245, Val loss 1.546\n",
      "Ep 1 (Step 010615): Train loss 1.295, Val loss 1.549\n",
      "Ep 1 (Step 010620): Train loss 1.122, Val loss 1.553\n",
      "Ep 1 (Step 010625): Train loss 1.174, Val loss 1.557\n",
      "Ep 1 (Step 010630): Train loss 1.155, Val loss 1.560\n",
      "Ep 1 (Step 010635): Train loss 1.226, Val loss 1.559\n",
      "Ep 1 (Step 010640): Train loss 1.265, Val loss 1.555\n",
      "Ep 1 (Step 010645): Train loss 1.258, Val loss 1.552\n",
      "Ep 1 (Step 010650): Train loss 1.271, Val loss 1.550\n",
      "Ep 1 (Step 010655): Train loss 1.237, Val loss 1.548\n",
      "Ep 1 (Step 010660): Train loss 1.218, Val loss 1.549\n",
      "Ep 1 (Step 010665): Train loss 1.245, Val loss 1.550\n",
      "Ep 1 (Step 010670): Train loss 1.276, Val loss 1.549\n",
      "Ep 1 (Step 010675): Train loss 1.237, Val loss 1.547\n",
      "Ep 1 (Step 010680): Train loss 1.307, Val loss 1.544\n",
      "Ep 1 (Step 010685): Train loss 1.385, Val loss 1.546\n",
      "Ep 1 (Step 010690): Train loss 1.270, Val loss 1.550\n",
      "Ep 1 (Step 010695): Train loss 1.256, Val loss 1.550\n",
      "Ep 1 (Step 010700): Train loss 1.217, Val loss 1.547\n",
      "Ep 1 (Step 010705): Train loss 1.337, Val loss 1.544\n",
      "Ep 1 (Step 010710): Train loss 1.150, Val loss 1.544\n",
      "Ep 1 (Step 010715): Train loss 1.317, Val loss 1.544\n",
      "Ep 1 (Step 010720): Train loss 1.204, Val loss 1.545\n",
      "Ep 1 (Step 010725): Train loss 1.216, Val loss 1.544\n",
      "Ep 1 (Step 010730): Train loss 1.186, Val loss 1.543\n",
      "Ep 1 (Step 010735): Train loss 1.108, Val loss 1.542\n",
      "Ep 1 (Step 010740): Train loss 1.163, Val loss 1.543\n",
      "Ep 1 (Step 010745): Train loss 1.262, Val loss 1.543\n",
      "Ep 1 (Step 010750): Train loss 1.092, Val loss 1.545\n",
      "Ep 1 (Step 010755): Train loss 1.318, Val loss 1.545\n",
      "Ep 1 (Step 010760): Train loss 1.251, Val loss 1.545\n",
      "Ep 1 (Step 010765): Train loss 1.218, Val loss 1.546\n",
      "Ep 1 (Step 010770): Train loss 1.155, Val loss 1.547\n",
      "Ep 1 (Step 010775): Train loss 1.164, Val loss 1.547\n",
      "Ep 1 (Step 010780): Train loss 1.366, Val loss 1.549\n",
      "Ep 1 (Step 010785): Train loss 1.204, Val loss 1.547\n",
      "Ep 1 (Step 010790): Train loss 1.243, Val loss 1.545\n",
      "Ep 1 (Step 010795): Train loss 1.176, Val loss 1.545\n",
      "Ep 1 (Step 010800): Train loss 1.378, Val loss 1.544\n",
      "Ep 1 (Step 010805): Train loss 1.014, Val loss 1.544\n",
      "Ep 1 (Step 010810): Train loss 1.247, Val loss 1.546\n",
      "Ep 1 (Step 010815): Train loss 1.049, Val loss 1.548\n",
      "Ep 1 (Step 010820): Train loss 1.266, Val loss 1.548\n",
      "Ep 1 (Step 010825): Train loss 1.180, Val loss 1.549\n",
      "Ep 1 (Step 010830): Train loss 1.250, Val loss 1.549\n",
      "Ep 1 (Step 010835): Train loss 1.227, Val loss 1.550\n",
      "Ep 1 (Step 010840): Train loss 1.291, Val loss 1.550\n",
      "Ep 1 (Step 010845): Train loss 1.058, Val loss 1.550\n",
      "Ep 1 (Step 010850): Train loss 1.405, Val loss 1.549\n",
      "Ep 1 (Step 010855): Train loss 1.286, Val loss 1.549\n",
      "Ep 1 (Step 010860): Train loss 1.056, Val loss 1.552\n",
      "Ep 1 (Step 010865): Train loss 1.225, Val loss 1.553\n",
      "Ep 1 (Step 010870): Train loss 1.360, Val loss 1.550\n",
      "Ep 1 (Step 010875): Train loss 1.306, Val loss 1.547\n",
      "Ep 1 (Step 010880): Train loss 1.298, Val loss 1.544\n",
      "Ep 1 (Step 010885): Train loss 1.183, Val loss 1.542\n",
      "Ep 1 (Step 010890): Train loss 1.186, Val loss 1.539\n",
      "Ep 1 (Step 010895): Train loss 1.130, Val loss 1.537\n",
      "Ep 1 (Step 010900): Train loss 1.447, Val loss 1.536\n",
      "Ep 1 (Step 010905): Train loss 1.214, Val loss 1.535\n",
      "Ep 1 (Step 010910): Train loss 1.294, Val loss 1.535\n",
      "Ep 1 (Step 010915): Train loss 1.132, Val loss 1.536\n",
      "Ep 1 (Step 010920): Train loss 1.101, Val loss 1.536\n",
      "Ep 1 (Step 010925): Train loss 1.316, Val loss 1.536\n",
      "Ep 1 (Step 010930): Train loss 1.114, Val loss 1.536\n",
      "Ep 1 (Step 010935): Train loss 1.268, Val loss 1.535\n",
      "Ep 1 (Step 010940): Train loss 1.115, Val loss 1.531\n",
      "Ep 1 (Step 010945): Train loss 1.280, Val loss 1.529\n",
      "Ep 1 (Step 010950): Train loss 1.143, Val loss 1.530\n",
      "Ep 1 (Step 010955): Train loss 1.063, Val loss 1.532\n",
      "Ep 1 (Step 010960): Train loss 1.245, Val loss 1.535\n",
      "Ep 1 (Step 010965): Train loss 1.024, Val loss 1.536\n",
      "Ep 1 (Step 010970): Train loss 1.380, Val loss 1.538\n",
      "Ep 1 (Step 010975): Train loss 1.180, Val loss 1.540\n",
      "Ep 1 (Step 010980): Train loss 1.338, Val loss 1.541\n",
      "Ep 1 (Step 010985): Train loss 1.345, Val loss 1.543\n",
      "Ep 1 (Step 010990): Train loss 1.253, Val loss 1.544\n",
      "Ep 1 (Step 010995): Train loss 1.262, Val loss 1.544\n",
      "Ep 1 (Step 011000): Train loss 1.162, Val loss 1.544\n",
      "Checkpoint saved: checkpoints/ckpt_step11000.pt\n",
      "Ep 1 (Step 011005): Train loss 1.371, Val loss 1.543\n",
      "Ep 1 (Step 011010): Train loss 1.149, Val loss 1.542\n",
      "Ep 1 (Step 011015): Train loss 1.322, Val loss 1.541\n",
      "Ep 1 (Step 011020): Train loss 1.061, Val loss 1.540\n",
      "Ep 1 (Step 011025): Train loss 1.169, Val loss 1.541\n",
      "Ep 1 (Step 011030): Train loss 1.419, Val loss 1.542\n",
      "Ep 1 (Step 011035): Train loss 1.181, Val loss 1.543\n",
      "Ep 1 (Step 011040): Train loss 1.287, Val loss 1.543\n",
      "Ep 1 (Step 011045): Train loss 1.258, Val loss 1.543\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Explain how using transitional words help in writing ### Input: \"<noinput>\" ### Response: Using transitional words can help in writing by providing a sense of continuity and continuity in the text. For example, \"The cat was sleeping\" can be used to create a sense of continuity in the text, while \"The cat was sleeping\" can be\n",
      "Epoch 1 checkpoint saved: checkpoints/ckpt_epoch1_step11046.pt\n",
      "Ep 2 (Step 011050): Train loss 1.083, Val loss 1.545\n",
      "Ep 2 (Step 011055): Train loss 1.405, Val loss 1.547\n",
      "Ep 2 (Step 011060): Train loss 1.366, Val loss 1.551\n",
      "Ep 2 (Step 011065): Train loss 1.119, Val loss 1.552\n",
      "Ep 2 (Step 011070): Train loss 1.046, Val loss 1.554\n",
      "Ep 2 (Step 011075): Train loss 1.343, Val loss 1.558\n",
      "Ep 2 (Step 011080): Train loss 1.195, Val loss 1.562\n",
      "Ep 2 (Step 011085): Train loss 1.141, Val loss 1.563\n",
      "Ep 2 (Step 011090): Train loss 1.256, Val loss 1.563\n",
      "Ep 2 (Step 011095): Train loss 1.301, Val loss 1.567\n",
      "Ep 2 (Step 011100): Train loss 1.150, Val loss 1.576\n",
      "Ep 2 (Step 011105): Train loss 1.391, Val loss 1.585\n",
      "Ep 2 (Step 011110): Train loss 1.314, Val loss 1.589\n",
      "Ep 2 (Step 011115): Train loss 1.159, Val loss 1.592\n",
      "Ep 2 (Step 011120): Train loss 1.190, Val loss 1.593\n",
      "Ep 2 (Step 011125): Train loss 1.202, Val loss 1.594\n",
      "Ep 2 (Step 011130): Train loss 1.165, Val loss 1.593\n",
      "Ep 2 (Step 011135): Train loss 1.240, Val loss 1.592\n",
      "Ep 2 (Step 011140): Train loss 1.217, Val loss 1.590\n",
      "Ep 2 (Step 011145): Train loss 1.203, Val loss 1.587\n",
      "Ep 2 (Step 011150): Train loss 1.208, Val loss 1.584\n",
      "Ep 2 (Step 011155): Train loss 1.201, Val loss 1.583\n",
      "Ep 2 (Step 011160): Train loss 1.217, Val loss 1.582\n",
      "Ep 2 (Step 011165): Train loss 1.161, Val loss 1.584\n",
      "Ep 2 (Step 011170): Train loss 1.196, Val loss 1.590\n",
      "Ep 2 (Step 011175): Train loss 1.262, Val loss 1.588\n",
      "Ep 2 (Step 011180): Train loss 1.237, Val loss 1.579\n",
      "Ep 2 (Step 011185): Train loss 1.277, Val loss 1.568\n",
      "Ep 2 (Step 011190): Train loss 1.141, Val loss 1.562\n",
      "Ep 2 (Step 011195): Train loss 0.996, Val loss 1.558\n",
      "Ep 2 (Step 011200): Train loss 1.097, Val loss 1.558\n",
      "Ep 2 (Step 011205): Train loss 1.218, Val loss 1.562\n",
      "Ep 2 (Step 011210): Train loss 1.080, Val loss 1.565\n",
      "Ep 2 (Step 011215): Train loss 1.080, Val loss 1.567\n",
      "Ep 2 (Step 011220): Train loss 1.193, Val loss 1.568\n",
      "Ep 2 (Step 011225): Train loss 1.255, Val loss 1.567\n",
      "Ep 2 (Step 011230): Train loss 1.171, Val loss 1.564\n",
      "Ep 2 (Step 011235): Train loss 1.297, Val loss 1.562\n",
      "Ep 2 (Step 011240): Train loss 1.162, Val loss 1.558\n",
      "Ep 2 (Step 011245): Train loss 1.284, Val loss 1.554\n",
      "Ep 2 (Step 011250): Train loss 1.460, Val loss 1.552\n",
      "Ep 2 (Step 011255): Train loss 1.256, Val loss 1.551\n",
      "Ep 2 (Step 011260): Train loss 1.155, Val loss 1.551\n",
      "Ep 2 (Step 011265): Train loss 1.298, Val loss 1.553\n",
      "Ep 2 (Step 011270): Train loss 1.231, Val loss 1.555\n",
      "Ep 2 (Step 011275): Train loss 1.162, Val loss 1.553\n",
      "Ep 2 (Step 011280): Train loss 1.223, Val loss 1.550\n",
      "Ep 2 (Step 011285): Train loss 1.212, Val loss 1.548\n",
      "Ep 2 (Step 011290): Train loss 1.163, Val loss 1.548\n",
      "Ep 2 (Step 011295): Train loss 1.248, Val loss 1.548\n",
      "Ep 2 (Step 011300): Train loss 1.127, Val loss 1.548\n",
      "Ep 2 (Step 011305): Train loss 1.203, Val loss 1.548\n",
      "Ep 2 (Step 011310): Train loss 1.296, Val loss 1.553\n",
      "Ep 2 (Step 011315): Train loss 1.330, Val loss 1.557\n",
      "Ep 2 (Step 011320): Train loss 1.250, Val loss 1.563\n",
      "Ep 2 (Step 011325): Train loss 1.213, Val loss 1.565\n",
      "Ep 2 (Step 011330): Train loss 1.228, Val loss 1.564\n",
      "Ep 2 (Step 011335): Train loss 1.217, Val loss 1.559\n",
      "Ep 2 (Step 011340): Train loss 1.288, Val loss 1.558\n",
      "Ep 2 (Step 011345): Train loss 1.153, Val loss 1.558\n",
      "Ep 2 (Step 011350): Train loss 1.195, Val loss 1.557\n",
      "Ep 2 (Step 011355): Train loss 1.437, Val loss 1.557\n",
      "Ep 2 (Step 011360): Train loss 1.135, Val loss 1.554\n",
      "Ep 2 (Step 011365): Train loss 1.137, Val loss 1.553\n",
      "Ep 2 (Step 011370): Train loss 1.129, Val loss 1.551\n",
      "Ep 2 (Step 011375): Train loss 1.064, Val loss 1.550\n",
      "Ep 2 (Step 011380): Train loss 1.168, Val loss 1.548\n",
      "Ep 2 (Step 011385): Train loss 1.103, Val loss 1.548\n",
      "Ep 2 (Step 011390): Train loss 1.053, Val loss 1.548\n",
      "Ep 2 (Step 011395): Train loss 1.326, Val loss 1.549\n",
      "Ep 2 (Step 011400): Train loss 1.045, Val loss 1.547\n",
      "Ep 2 (Step 011405): Train loss 1.256, Val loss 1.547\n",
      "Ep 2 (Step 011410): Train loss 1.348, Val loss 1.546\n",
      "Ep 2 (Step 011415): Train loss 1.170, Val loss 1.547\n",
      "Ep 2 (Step 011420): Train loss 1.361, Val loss 1.547\n",
      "Ep 2 (Step 011425): Train loss 1.145, Val loss 1.546\n",
      "Ep 2 (Step 011430): Train loss 1.234, Val loss 1.545\n",
      "Ep 2 (Step 011435): Train loss 1.202, Val loss 1.546\n",
      "Ep 2 (Step 011440): Train loss 1.044, Val loss 1.547\n",
      "Ep 2 (Step 011445): Train loss 1.113, Val loss 1.550\n",
      "Ep 2 (Step 011450): Train loss 1.347, Val loss 1.551\n",
      "Ep 2 (Step 011455): Train loss 1.236, Val loss 1.552\n",
      "Ep 2 (Step 011460): Train loss 1.154, Val loss 1.554\n",
      "Ep 2 (Step 011465): Train loss 1.172, Val loss 1.556\n",
      "Ep 2 (Step 011470): Train loss 1.233, Val loss 1.558\n",
      "Ep 2 (Step 011475): Train loss 1.275, Val loss 1.560\n",
      "Ep 2 (Step 011480): Train loss 1.249, Val loss 1.558\n",
      "Ep 2 (Step 011485): Train loss 1.342, Val loss 1.552\n",
      "Ep 2 (Step 011490): Train loss 1.223, Val loss 1.546\n",
      "Ep 2 (Step 011495): Train loss 1.241, Val loss 1.543\n",
      "Ep 2 (Step 011500): Train loss 1.222, Val loss 1.541\n",
      "Ep 2 (Step 011505): Train loss 1.169, Val loss 1.541\n",
      "Ep 2 (Step 011510): Train loss 1.269, Val loss 1.542\n",
      "Ep 2 (Step 011515): Train loss 1.323, Val loss 1.544\n",
      "Ep 2 (Step 011520): Train loss 1.150, Val loss 1.545\n",
      "Ep 2 (Step 011525): Train loss 1.416, Val loss 1.547\n",
      "Ep 2 (Step 011530): Train loss 1.228, Val loss 1.548\n",
      "Ep 2 (Step 011535): Train loss 0.918, Val loss 1.550\n",
      "Ep 2 (Step 011540): Train loss 1.343, Val loss 1.548\n",
      "Ep 2 (Step 011545): Train loss 0.918, Val loss 1.546\n",
      "Ep 2 (Step 011550): Train loss 1.200, Val loss 1.548\n",
      "Ep 2 (Step 011555): Train loss 1.187, Val loss 1.550\n",
      "Ep 2 (Step 011560): Train loss 1.180, Val loss 1.551\n",
      "Ep 2 (Step 011565): Train loss 1.127, Val loss 1.550\n",
      "Ep 2 (Step 011570): Train loss 1.226, Val loss 1.550\n",
      "Ep 2 (Step 011575): Train loss 1.264, Val loss 1.552\n",
      "Ep 2 (Step 011580): Train loss 1.280, Val loss 1.549\n",
      "Ep 2 (Step 011585): Train loss 1.213, Val loss 1.549\n",
      "Ep 2 (Step 011590): Train loss 1.046, Val loss 1.552\n",
      "Ep 2 (Step 011595): Train loss 1.096, Val loss 1.553\n",
      "Ep 2 (Step 011600): Train loss 1.213, Val loss 1.553\n",
      "Ep 2 (Step 011605): Train loss 1.294, Val loss 1.552\n",
      "Ep 2 (Step 011610): Train loss 1.206, Val loss 1.552\n",
      "Ep 2 (Step 011615): Train loss 1.412, Val loss 1.551\n",
      "Ep 2 (Step 011620): Train loss 1.261, Val loss 1.548\n",
      "Ep 2 (Step 011625): Train loss 1.225, Val loss 1.548\n",
      "Ep 2 (Step 011630): Train loss 1.313, Val loss 1.549\n",
      "Ep 2 (Step 011635): Train loss 1.290, Val loss 1.551\n",
      "Ep 2 (Step 011640): Train loss 1.369, Val loss 1.553\n",
      "Ep 2 (Step 011645): Train loss 1.310, Val loss 1.555\n",
      "Ep 2 (Step 011650): Train loss 1.206, Val loss 1.555\n",
      "Ep 2 (Step 011655): Train loss 1.177, Val loss 1.554\n",
      "Ep 2 (Step 011660): Train loss 1.275, Val loss 1.552\n",
      "Ep 2 (Step 011665): Train loss 1.040, Val loss 1.551\n",
      "Ep 2 (Step 011670): Train loss 1.133, Val loss 1.552\n",
      "Ep 2 (Step 011675): Train loss 1.094, Val loss 1.553\n",
      "Ep 2 (Step 011680): Train loss 1.221, Val loss 1.554\n",
      "Ep 2 (Step 011685): Train loss 1.098, Val loss 1.552\n",
      "Ep 2 (Step 011690): Train loss 1.192, Val loss 1.550\n",
      "Ep 2 (Step 011695): Train loss 1.235, Val loss 1.549\n",
      "Ep 2 (Step 011700): Train loss 1.220, Val loss 1.549\n",
      "Ep 2 (Step 011705): Train loss 1.289, Val loss 1.550\n",
      "Ep 2 (Step 011710): Train loss 1.375, Val loss 1.550\n",
      "Ep 2 (Step 011715): Train loss 1.119, Val loss 1.549\n",
      "Ep 2 (Step 011720): Train loss 1.204, Val loss 1.547\n",
      "Ep 2 (Step 011725): Train loss 1.093, Val loss 1.546\n",
      "Ep 2 (Step 011730): Train loss 1.071, Val loss 1.546\n",
      "Ep 2 (Step 011735): Train loss 1.211, Val loss 1.547\n",
      "Ep 2 (Step 011740): Train loss 1.121, Val loss 1.548\n",
      "Ep 2 (Step 011745): Train loss 1.272, Val loss 1.549\n",
      "Ep 2 (Step 011750): Train loss 1.390, Val loss 1.550\n",
      "Ep 2 (Step 011755): Train loss 1.172, Val loss 1.549\n",
      "Ep 2 (Step 011760): Train loss 1.209, Val loss 1.548\n",
      "Ep 2 (Step 011765): Train loss 1.283, Val loss 1.548\n",
      "Ep 2 (Step 011770): Train loss 1.093, Val loss 1.549\n",
      "Ep 2 (Step 011775): Train loss 1.237, Val loss 1.549\n",
      "Ep 2 (Step 011780): Train loss 1.270, Val loss 1.549\n",
      "Ep 2 (Step 011785): Train loss 1.369, Val loss 1.549\n",
      "Ep 2 (Step 011790): Train loss 1.191, Val loss 1.547\n",
      "Ep 2 (Step 011795): Train loss 1.197, Val loss 1.548\n",
      "Ep 2 (Step 011800): Train loss 1.134, Val loss 1.551\n",
      "Ep 2 (Step 011805): Train loss 1.193, Val loss 1.551\n",
      "Ep 2 (Step 011810): Train loss 1.224, Val loss 1.550\n",
      "Ep 2 (Step 011815): Train loss 1.108, Val loss 1.549\n",
      "Ep 2 (Step 011820): Train loss 1.131, Val loss 1.549\n",
      "Ep 2 (Step 011825): Train loss 1.263, Val loss 1.550\n",
      "Ep 2 (Step 011830): Train loss 1.237, Val loss 1.551\n",
      "Ep 2 (Step 011835): Train loss 1.276, Val loss 1.552\n",
      "Ep 2 (Step 011840): Train loss 1.285, Val loss 1.551\n",
      "Ep 2 (Step 011845): Train loss 1.199, Val loss 1.551\n",
      "Ep 2 (Step 011850): Train loss 1.139, Val loss 1.550\n",
      "Ep 2 (Step 011855): Train loss 1.229, Val loss 1.550\n",
      "Ep 2 (Step 011860): Train loss 1.166, Val loss 1.547\n",
      "Ep 2 (Step 011865): Train loss 1.255, Val loss 1.544\n",
      "Ep 2 (Step 011870): Train loss 1.002, Val loss 1.542\n",
      "Ep 2 (Step 011875): Train loss 1.066, Val loss 1.543\n",
      "Ep 2 (Step 011880): Train loss 1.146, Val loss 1.545\n",
      "Ep 2 (Step 011885): Train loss 1.161, Val loss 1.547\n",
      "Ep 2 (Step 011890): Train loss 1.320, Val loss 1.550\n",
      "Ep 2 (Step 011895): Train loss 1.088, Val loss 1.553\n",
      "Ep 2 (Step 011900): Train loss 1.107, Val loss 1.553\n",
      "Ep 2 (Step 011905): Train loss 1.092, Val loss 1.551\n",
      "Ep 2 (Step 011910): Train loss 1.249, Val loss 1.549\n",
      "Ep 2 (Step 011915): Train loss 1.208, Val loss 1.548\n",
      "Ep 2 (Step 011920): Train loss 1.035, Val loss 1.547\n",
      "Ep 2 (Step 011925): Train loss 1.061, Val loss 1.548\n",
      "Ep 2 (Step 011930): Train loss 1.188, Val loss 1.550\n",
      "Ep 2 (Step 011935): Train loss 1.169, Val loss 1.552\n",
      "Ep 2 (Step 011940): Train loss 1.185, Val loss 1.552\n",
      "Ep 2 (Step 011945): Train loss 1.308, Val loss 1.552\n",
      "Ep 2 (Step 011950): Train loss 1.298, Val loss 1.551\n",
      "Ep 2 (Step 011955): Train loss 1.086, Val loss 1.551\n",
      "Ep 2 (Step 011960): Train loss 1.018, Val loss 1.551\n",
      "Ep 2 (Step 011965): Train loss 1.176, Val loss 1.549\n",
      "Ep 2 (Step 011970): Train loss 1.267, Val loss 1.550\n",
      "Ep 2 (Step 011975): Train loss 1.107, Val loss 1.550\n",
      "Ep 2 (Step 011980): Train loss 1.081, Val loss 1.549\n",
      "Ep 2 (Step 011985): Train loss 1.118, Val loss 1.550\n",
      "Ep 2 (Step 011990): Train loss 1.176, Val loss 1.549\n",
      "Ep 2 (Step 011995): Train loss 1.256, Val loss 1.549\n",
      "Ep 2 (Step 012000): Train loss 1.241, Val loss 1.549\n",
      "Checkpoint saved: checkpoints/ckpt_step12000.pt\n",
      "Removed old checkpoint: checkpoints/ckpt_step11000.pt\n",
      "Ep 2 (Step 012005): Train loss 1.255, Val loss 1.553\n",
      "Ep 2 (Step 012010): Train loss 1.264, Val loss 1.556\n",
      "Ep 2 (Step 012015): Train loss 1.353, Val loss 1.554\n",
      "Ep 2 (Step 012020): Train loss 1.122, Val loss 1.552\n",
      "Ep 2 (Step 012025): Train loss 1.240, Val loss 1.550\n",
      "Ep 2 (Step 012030): Train loss 1.291, Val loss 1.550\n",
      "Ep 2 (Step 012035): Train loss 1.231, Val loss 1.549\n",
      "Ep 2 (Step 012040): Train loss 1.159, Val loss 1.548\n",
      "Ep 2 (Step 012045): Train loss 1.335, Val loss 1.547\n",
      "Ep 2 (Step 012050): Train loss 1.162, Val loss 1.546\n",
      "Ep 2 (Step 012055): Train loss 1.556, Val loss 1.548\n",
      "Ep 2 (Step 012060): Train loss 1.208, Val loss 1.548\n",
      "Ep 2 (Step 012065): Train loss 1.236, Val loss 1.550\n",
      "Ep 2 (Step 012070): Train loss 1.129, Val loss 1.551\n",
      "Ep 2 (Step 012075): Train loss 1.222, Val loss 1.552\n",
      "Ep 2 (Step 012080): Train loss 1.233, Val loss 1.552\n",
      "Ep 2 (Step 012085): Train loss 1.322, Val loss 1.554\n",
      "Ep 2 (Step 012090): Train loss 1.094, Val loss 1.556\n",
      "Ep 2 (Step 012095): Train loss 1.191, Val loss 1.557\n",
      "Ep 2 (Step 012100): Train loss 1.184, Val loss 1.559\n",
      "Ep 2 (Step 012105): Train loss 1.088, Val loss 1.561\n",
      "Ep 2 (Step 012110): Train loss 1.092, Val loss 1.562\n",
      "Ep 2 (Step 012115): Train loss 1.159, Val loss 1.558\n",
      "Ep 2 (Step 012120): Train loss 1.257, Val loss 1.558\n",
      "Ep 2 (Step 012125): Train loss 1.245, Val loss 1.559\n",
      "Ep 2 (Step 012130): Train loss 1.238, Val loss 1.557\n",
      "Ep 2 (Step 012135): Train loss 1.293, Val loss 1.556\n",
      "Ep 2 (Step 012140): Train loss 1.160, Val loss 1.556\n",
      "Ep 2 (Step 012145): Train loss 1.239, Val loss 1.555\n",
      "Ep 2 (Step 012150): Train loss 1.209, Val loss 1.552\n",
      "Ep 2 (Step 012155): Train loss 1.046, Val loss 1.548\n",
      "Ep 2 (Step 012160): Train loss 1.246, Val loss 1.544\n",
      "Ep 2 (Step 012165): Train loss 1.194, Val loss 1.542\n",
      "Ep 2 (Step 012170): Train loss 1.313, Val loss 1.544\n",
      "Ep 2 (Step 012175): Train loss 1.143, Val loss 1.547\n",
      "Ep 2 (Step 012180): Train loss 1.339, Val loss 1.549\n",
      "Ep 2 (Step 012185): Train loss 1.248, Val loss 1.551\n",
      "Ep 2 (Step 012190): Train loss 1.328, Val loss 1.552\n",
      "Ep 2 (Step 012195): Train loss 1.338, Val loss 1.554\n",
      "Ep 2 (Step 012200): Train loss 1.143, Val loss 1.553\n",
      "Ep 2 (Step 012205): Train loss 1.268, Val loss 1.552\n",
      "Ep 2 (Step 012210): Train loss 1.095, Val loss 1.547\n",
      "Ep 2 (Step 012215): Train loss 1.104, Val loss 1.546\n",
      "Ep 2 (Step 012220): Train loss 1.203, Val loss 1.544\n",
      "Ep 2 (Step 012225): Train loss 0.981, Val loss 1.544\n",
      "Ep 2 (Step 012230): Train loss 1.198, Val loss 1.544\n",
      "Ep 2 (Step 012235): Train loss 1.240, Val loss 1.542\n",
      "Ep 2 (Step 012240): Train loss 1.297, Val loss 1.542\n",
      "Ep 2 (Step 012245): Train loss 1.219, Val loss 1.543\n",
      "Ep 2 (Step 012250): Train loss 1.099, Val loss 1.544\n",
      "Ep 2 (Step 012255): Train loss 1.168, Val loss 1.542\n",
      "Ep 2 (Step 012260): Train loss 1.118, Val loss 1.542\n",
      "Ep 2 (Step 012265): Train loss 1.301, Val loss 1.541\n",
      "Ep 2 (Step 012270): Train loss 1.158, Val loss 1.541\n",
      "Ep 2 (Step 012275): Train loss 1.156, Val loss 1.541\n",
      "Ep 2 (Step 012280): Train loss 1.153, Val loss 1.541\n",
      "Ep 2 (Step 012285): Train loss 1.215, Val loss 1.540\n",
      "Ep 2 (Step 012290): Train loss 1.171, Val loss 1.540\n",
      "Ep 2 (Step 012295): Train loss 1.441, Val loss 1.538\n",
      "Ep 2 (Step 012300): Train loss 1.119, Val loss 1.536\n",
      "Ep 2 (Step 012305): Train loss 1.151, Val loss 1.536\n",
      "Ep 2 (Step 012310): Train loss 1.120, Val loss 1.536\n",
      "Ep 2 (Step 012315): Train loss 1.137, Val loss 1.537\n",
      "Ep 2 (Step 012320): Train loss 1.290, Val loss 1.538\n",
      "Ep 2 (Step 012325): Train loss 1.235, Val loss 1.538\n",
      "Ep 2 (Step 012330): Train loss 1.241, Val loss 1.538\n",
      "Ep 2 (Step 012335): Train loss 1.142, Val loss 1.538\n",
      "Ep 2 (Step 012340): Train loss 1.318, Val loss 1.539\n",
      "Ep 2 (Step 012345): Train loss 1.121, Val loss 1.540\n",
      "Ep 2 (Step 012350): Train loss 1.249, Val loss 1.539\n",
      "Ep 2 (Step 012355): Train loss 1.094, Val loss 1.540\n",
      "Ep 2 (Step 012360): Train loss 1.197, Val loss 1.541\n",
      "Ep 2 (Step 012365): Train loss 1.268, Val loss 1.541\n",
      "Ep 2 (Step 012370): Train loss 1.343, Val loss 1.543\n",
      "Ep 2 (Step 012375): Train loss 1.044, Val loss 1.541\n",
      "Ep 2 (Step 012380): Train loss 1.090, Val loss 1.541\n",
      "Ep 2 (Step 012385): Train loss 1.315, Val loss 1.541\n",
      "Ep 2 (Step 012390): Train loss 1.143, Val loss 1.540\n",
      "Ep 2 (Step 012395): Train loss 1.125, Val loss 1.541\n",
      "Ep 2 (Step 012400): Train loss 1.244, Val loss 1.540\n",
      "Ep 2 (Step 012405): Train loss 1.183, Val loss 1.536\n",
      "Ep 2 (Step 012410): Train loss 1.277, Val loss 1.534\n",
      "Ep 2 (Step 012415): Train loss 1.122, Val loss 1.534\n",
      "Ep 2 (Step 012420): Train loss 1.250, Val loss 1.535\n",
      "Ep 2 (Step 012425): Train loss 1.233, Val loss 1.534\n",
      "Ep 2 (Step 012430): Train loss 1.004, Val loss 1.531\n",
      "Ep 2 (Step 012435): Train loss 1.150, Val loss 1.530\n",
      "Ep 2 (Step 012440): Train loss 1.183, Val loss 1.531\n",
      "Ep 2 (Step 012445): Train loss 1.119, Val loss 1.532\n",
      "Ep 2 (Step 012450): Train loss 1.301, Val loss 1.532\n",
      "Ep 2 (Step 012455): Train loss 1.276, Val loss 1.534\n",
      "Ep 2 (Step 012460): Train loss 1.288, Val loss 1.537\n",
      "Ep 2 (Step 012465): Train loss 1.251, Val loss 1.542\n",
      "Ep 2 (Step 012470): Train loss 1.301, Val loss 1.545\n",
      "Ep 2 (Step 012475): Train loss 1.247, Val loss 1.546\n",
      "Ep 2 (Step 012480): Train loss 1.118, Val loss 1.545\n",
      "Ep 2 (Step 012485): Train loss 1.356, Val loss 1.543\n",
      "Ep 2 (Step 012490): Train loss 1.219, Val loss 1.542\n",
      "Ep 2 (Step 012495): Train loss 1.225, Val loss 1.538\n",
      "Ep 2 (Step 012500): Train loss 1.151, Val loss 1.534\n",
      "Ep 2 (Step 012505): Train loss 1.196, Val loss 1.533\n",
      "Ep 2 (Step 012510): Train loss 1.225, Val loss 1.533\n",
      "Ep 2 (Step 012515): Train loss 1.221, Val loss 1.534\n",
      "Ep 2 (Step 012520): Train loss 1.333, Val loss 1.534\n",
      "Ep 2 (Step 012525): Train loss 1.135, Val loss 1.533\n",
      "Ep 2 (Step 012530): Train loss 1.112, Val loss 1.533\n",
      "Ep 2 (Step 012535): Train loss 1.219, Val loss 1.534\n",
      "Ep 2 (Step 012540): Train loss 1.250, Val loss 1.535\n",
      "Ep 2 (Step 012545): Train loss 1.080, Val loss 1.537\n",
      "Ep 2 (Step 012550): Train loss 1.198, Val loss 1.540\n",
      "Ep 2 (Step 012555): Train loss 1.266, Val loss 1.538\n",
      "Ep 2 (Step 012560): Train loss 1.318, Val loss 1.536\n",
      "Ep 2 (Step 012565): Train loss 1.176, Val loss 1.535\n",
      "Ep 2 (Step 012570): Train loss 1.153, Val loss 1.535\n",
      "Ep 2 (Step 012575): Train loss 1.159, Val loss 1.536\n",
      "Ep 2 (Step 012580): Train loss 1.276, Val loss 1.537\n",
      "Ep 2 (Step 012585): Train loss 1.335, Val loss 1.536\n",
      "Ep 2 (Step 012590): Train loss 1.308, Val loss 1.538\n",
      "Ep 2 (Step 012595): Train loss 1.144, Val loss 1.539\n",
      "Ep 2 (Step 012600): Train loss 1.072, Val loss 1.540\n",
      "Ep 2 (Step 012605): Train loss 1.243, Val loss 1.542\n",
      "Ep 2 (Step 012610): Train loss 1.086, Val loss 1.545\n",
      "Ep 2 (Step 012615): Train loss 1.181, Val loss 1.543\n",
      "Ep 2 (Step 012620): Train loss 1.232, Val loss 1.543\n",
      "Ep 2 (Step 012625): Train loss 1.084, Val loss 1.545\n",
      "Ep 2 (Step 012630): Train loss 1.046, Val loss 1.544\n",
      "Ep 2 (Step 012635): Train loss 1.212, Val loss 1.542\n",
      "Ep 2 (Step 012640): Train loss 1.262, Val loss 1.542\n",
      "Ep 2 (Step 012645): Train loss 1.306, Val loss 1.541\n",
      "Ep 2 (Step 012650): Train loss 1.091, Val loss 1.542\n",
      "Ep 2 (Step 012655): Train loss 1.348, Val loss 1.544\n",
      "Ep 2 (Step 012660): Train loss 1.273, Val loss 1.545\n",
      "Ep 2 (Step 012665): Train loss 1.260, Val loss 1.546\n",
      "Ep 2 (Step 012670): Train loss 1.329, Val loss 1.546\n",
      "Ep 2 (Step 012675): Train loss 1.214, Val loss 1.546\n",
      "Ep 2 (Step 012680): Train loss 1.139, Val loss 1.548\n",
      "Ep 2 (Step 012685): Train loss 1.213, Val loss 1.550\n",
      "Ep 2 (Step 012690): Train loss 1.211, Val loss 1.551\n",
      "Ep 2 (Step 012695): Train loss 1.062, Val loss 1.552\n",
      "Ep 2 (Step 012700): Train loss 1.241, Val loss 1.550\n",
      "Ep 2 (Step 012705): Train loss 1.277, Val loss 1.547\n",
      "Ep 2 (Step 012710): Train loss 1.327, Val loss 1.546\n",
      "Ep 2 (Step 012715): Train loss 1.197, Val loss 1.545\n",
      "Ep 2 (Step 012720): Train loss 1.432, Val loss 1.546\n",
      "Ep 2 (Step 012725): Train loss 1.263, Val loss 1.548\n",
      "Ep 2 (Step 012730): Train loss 1.279, Val loss 1.548\n",
      "Ep 2 (Step 012735): Train loss 1.057, Val loss 1.548\n",
      "Ep 2 (Step 012740): Train loss 1.300, Val loss 1.549\n",
      "Ep 2 (Step 012745): Train loss 1.232, Val loss 1.550\n",
      "Ep 2 (Step 012750): Train loss 1.214, Val loss 1.551\n",
      "Ep 2 (Step 012755): Train loss 1.228, Val loss 1.551\n",
      "Ep 2 (Step 012760): Train loss 1.288, Val loss 1.547\n",
      "Ep 2 (Step 012765): Train loss 1.007, Val loss 1.546\n",
      "Ep 2 (Step 012770): Train loss 1.179, Val loss 1.546\n",
      "Ep 2 (Step 012775): Train loss 1.237, Val loss 1.546\n",
      "Ep 2 (Step 012780): Train loss 1.255, Val loss 1.548\n",
      "Ep 2 (Step 012785): Train loss 1.150, Val loss 1.550\n",
      "Ep 2 (Step 012790): Train loss 1.136, Val loss 1.552\n",
      "Ep 2 (Step 012795): Train loss 1.265, Val loss 1.553\n",
      "Ep 2 (Step 012800): Train loss 1.094, Val loss 1.553\n",
      "Ep 2 (Step 012805): Train loss 1.193, Val loss 1.553\n",
      "Ep 2 (Step 012810): Train loss 1.336, Val loss 1.552\n",
      "Ep 2 (Step 012815): Train loss 1.181, Val loss 1.550\n",
      "Ep 2 (Step 012820): Train loss 1.179, Val loss 1.547\n",
      "Ep 2 (Step 012825): Train loss 1.292, Val loss 1.545\n",
      "Ep 2 (Step 012830): Train loss 1.180, Val loss 1.544\n",
      "Ep 2 (Step 012835): Train loss 1.229, Val loss 1.543\n",
      "Ep 2 (Step 012840): Train loss 1.255, Val loss 1.543\n",
      "Ep 2 (Step 012845): Train loss 1.317, Val loss 1.544\n",
      "Ep 2 (Step 012850): Train loss 1.218, Val loss 1.544\n",
      "Ep 2 (Step 012855): Train loss 1.147, Val loss 1.545\n",
      "Ep 2 (Step 012860): Train loss 1.271, Val loss 1.546\n",
      "Ep 2 (Step 012865): Train loss 1.021, Val loss 1.548\n",
      "Ep 2 (Step 012870): Train loss 1.120, Val loss 1.548\n",
      "Ep 2 (Step 012875): Train loss 1.281, Val loss 1.547\n",
      "Ep 2 (Step 012880): Train loss 1.149, Val loss 1.548\n",
      "Ep 2 (Step 012885): Train loss 1.368, Val loss 1.548\n",
      "Ep 2 (Step 012890): Train loss 1.274, Val loss 1.546\n",
      "Ep 2 (Step 012895): Train loss 1.215, Val loss 1.544\n",
      "Ep 2 (Step 012900): Train loss 1.199, Val loss 1.542\n",
      "Ep 2 (Step 012905): Train loss 1.252, Val loss 1.544\n",
      "Ep 2 (Step 012910): Train loss 1.312, Val loss 1.551\n",
      "Ep 2 (Step 012915): Train loss 1.116, Val loss 1.555\n",
      "Ep 2 (Step 012920): Train loss 1.172, Val loss 1.560\n",
      "Ep 2 (Step 012925): Train loss 1.078, Val loss 1.557\n",
      "Ep 2 (Step 012930): Train loss 1.114, Val loss 1.556\n",
      "Ep 2 (Step 012935): Train loss 1.288, Val loss 1.557\n",
      "Ep 2 (Step 012940): Train loss 1.326, Val loss 1.558\n",
      "Ep 2 (Step 012945): Train loss 1.433, Val loss 1.557\n",
      "Ep 2 (Step 012950): Train loss 1.206, Val loss 1.554\n",
      "Ep 2 (Step 012955): Train loss 1.162, Val loss 1.553\n",
      "Ep 2 (Step 012960): Train loss 1.156, Val loss 1.553\n",
      "Ep 2 (Step 012965): Train loss 1.141, Val loss 1.555\n",
      "Ep 2 (Step 012970): Train loss 1.236, Val loss 1.558\n",
      "Ep 2 (Step 012975): Train loss 1.243, Val loss 1.557\n",
      "Ep 2 (Step 012980): Train loss 1.211, Val loss 1.554\n",
      "Ep 2 (Step 012985): Train loss 1.327, Val loss 1.551\n",
      "Ep 2 (Step 012990): Train loss 1.146, Val loss 1.550\n",
      "Ep 2 (Step 012995): Train loss 1.205, Val loss 1.549\n",
      "Ep 2 (Step 013000): Train loss 1.128, Val loss 1.549\n",
      "Checkpoint saved: checkpoints/ckpt_step13000.pt\n",
      "Removed old checkpoint: checkpoints/ckpt_epoch1_step11046.pt\n",
      "Ep 2 (Step 013005): Train loss 1.122, Val loss 1.547\n",
      "Ep 2 (Step 013010): Train loss 1.230, Val loss 1.545\n",
      "Ep 2 (Step 013015): Train loss 1.050, Val loss 1.543\n",
      "Ep 2 (Step 013020): Train loss 1.401, Val loss 1.542\n",
      "Ep 2 (Step 013025): Train loss 1.155, Val loss 1.542\n",
      "Ep 2 (Step 013030): Train loss 1.276, Val loss 1.542\n",
      "Ep 2 (Step 013035): Train loss 1.394, Val loss 1.542\n",
      "Ep 2 (Step 013040): Train loss 1.272, Val loss 1.541\n",
      "Ep 2 (Step 013045): Train loss 1.227, Val loss 1.541\n",
      "Ep 2 (Step 013050): Train loss 1.397, Val loss 1.541\n",
      "Ep 2 (Step 013055): Train loss 1.267, Val loss 1.540\n",
      "Ep 2 (Step 013060): Train loss 1.413, Val loss 1.538\n",
      "Ep 2 (Step 013065): Train loss 1.305, Val loss 1.539\n",
      "Ep 2 (Step 013070): Train loss 1.136, Val loss 1.540\n",
      "Ep 2 (Step 013075): Train loss 1.208, Val loss 1.540\n",
      "Ep 2 (Step 013080): Train loss 1.230, Val loss 1.540\n",
      "Ep 2 (Step 013085): Train loss 1.177, Val loss 1.540\n",
      "Ep 2 (Step 013090): Train loss 1.238, Val loss 1.539\n",
      "Ep 2 (Step 013095): Train loss 1.165, Val loss 1.540\n",
      "Ep 2 (Step 013100): Train loss 1.303, Val loss 1.539\n",
      "Ep 2 (Step 013105): Train loss 1.099, Val loss 1.538\n",
      "Ep 2 (Step 013110): Train loss 1.321, Val loss 1.539\n",
      "Ep 2 (Step 013115): Train loss 1.336, Val loss 1.540\n",
      "Ep 2 (Step 013120): Train loss 1.159, Val loss 1.539\n",
      "Ep 2 (Step 013125): Train loss 1.321, Val loss 1.539\n",
      "Ep 2 (Step 013130): Train loss 1.247, Val loss 1.538\n",
      "Ep 2 (Step 013135): Train loss 1.224, Val loss 1.539\n",
      "Ep 2 (Step 013140): Train loss 1.129, Val loss 1.540\n",
      "Ep 2 (Step 013145): Train loss 1.242, Val loss 1.541\n",
      "Ep 2 (Step 013150): Train loss 1.284, Val loss 1.541\n",
      "Ep 2 (Step 013155): Train loss 1.377, Val loss 1.540\n",
      "Ep 2 (Step 013160): Train loss 1.287, Val loss 1.539\n",
      "Ep 2 (Step 013165): Train loss 1.190, Val loss 1.537\n",
      "Ep 2 (Step 013170): Train loss 1.301, Val loss 1.536\n",
      "Ep 2 (Step 013175): Train loss 1.058, Val loss 1.535\n",
      "Ep 2 (Step 013180): Train loss 1.340, Val loss 1.534\n",
      "Ep 2 (Step 013185): Train loss 1.182, Val loss 1.534\n",
      "Ep 2 (Step 013190): Train loss 1.134, Val loss 1.533\n",
      "Ep 2 (Step 013195): Train loss 1.273, Val loss 1.532\n",
      "Ep 2 (Step 013200): Train loss 1.231, Val loss 1.532\n",
      "Ep 2 (Step 013205): Train loss 1.297, Val loss 1.532\n",
      "Ep 2 (Step 013210): Train loss 1.060, Val loss 1.532\n",
      "Ep 2 (Step 013215): Train loss 1.298, Val loss 1.531\n",
      "Ep 2 (Step 013220): Train loss 1.228, Val loss 1.531\n",
      "Ep 2 (Step 013225): Train loss 1.385, Val loss 1.534\n",
      "Ep 2 (Step 013230): Train loss 1.145, Val loss 1.536\n",
      "Ep 2 (Step 013235): Train loss 1.375, Val loss 1.541\n",
      "Ep 2 (Step 013240): Train loss 1.258, Val loss 1.545\n",
      "Ep 2 (Step 013245): Train loss 1.179, Val loss 1.544\n",
      "Ep 2 (Step 013250): Train loss 1.118, Val loss 1.543\n",
      "Ep 2 (Step 013255): Train loss 1.229, Val loss 1.541\n",
      "Ep 2 (Step 013260): Train loss 1.313, Val loss 1.540\n",
      "Ep 2 (Step 013265): Train loss 1.140, Val loss 1.537\n",
      "Ep 2 (Step 013270): Train loss 1.177, Val loss 1.536\n",
      "Ep 2 (Step 013275): Train loss 1.285, Val loss 1.535\n",
      "Ep 2 (Step 013280): Train loss 1.391, Val loss 1.535\n",
      "Ep 2 (Step 013285): Train loss 1.192, Val loss 1.536\n",
      "Ep 2 (Step 013290): Train loss 1.106, Val loss 1.536\n",
      "Ep 2 (Step 013295): Train loss 1.360, Val loss 1.537\n",
      "Ep 2 (Step 013300): Train loss 1.199, Val loss 1.540\n",
      "Ep 2 (Step 013305): Train loss 1.239, Val loss 1.540\n",
      "Ep 2 (Step 013310): Train loss 1.355, Val loss 1.539\n",
      "Ep 2 (Step 013315): Train loss 1.296, Val loss 1.538\n",
      "Ep 2 (Step 013320): Train loss 1.151, Val loss 1.535\n",
      "Ep 2 (Step 013325): Train loss 1.153, Val loss 1.535\n",
      "Ep 2 (Step 013330): Train loss 1.120, Val loss 1.537\n",
      "Ep 2 (Step 013335): Train loss 1.171, Val loss 1.538\n",
      "Ep 2 (Step 013340): Train loss 1.296, Val loss 1.538\n",
      "Ep 2 (Step 013345): Train loss 1.172, Val loss 1.537\n",
      "Ep 2 (Step 013350): Train loss 1.343, Val loss 1.536\n",
      "Ep 2 (Step 013355): Train loss 1.383, Val loss 1.536\n",
      "Ep 2 (Step 013360): Train loss 1.221, Val loss 1.537\n",
      "Ep 2 (Step 013365): Train loss 1.208, Val loss 1.537\n",
      "Ep 2 (Step 013370): Train loss 1.239, Val loss 1.536\n",
      "Ep 2 (Step 013375): Train loss 1.174, Val loss 1.536\n",
      "Ep 2 (Step 013380): Train loss 1.210, Val loss 1.537\n",
      "Ep 2 (Step 013385): Train loss 1.325, Val loss 1.541\n",
      "Ep 2 (Step 013390): Train loss 1.218, Val loss 1.543\n",
      "Ep 2 (Step 013395): Train loss 1.198, Val loss 1.545\n",
      "Ep 2 (Step 013400): Train loss 1.401, Val loss 1.545\n",
      "Ep 2 (Step 013405): Train loss 1.292, Val loss 1.544\n",
      "Ep 2 (Step 013410): Train loss 1.280, Val loss 1.542\n",
      "Ep 2 (Step 013415): Train loss 1.256, Val loss 1.541\n",
      "Ep 2 (Step 013420): Train loss 1.311, Val loss 1.539\n",
      "Ep 2 (Step 013425): Train loss 1.305, Val loss 1.538\n",
      "Ep 2 (Step 013430): Train loss 1.149, Val loss 1.543\n",
      "Ep 2 (Step 013435): Train loss 1.257, Val loss 1.546\n",
      "Ep 2 (Step 013440): Train loss 1.339, Val loss 1.546\n",
      "Ep 2 (Step 013445): Train loss 1.253, Val loss 1.547\n",
      "Ep 2 (Step 013450): Train loss 1.187, Val loss 1.547\n",
      "Ep 2 (Step 013455): Train loss 1.238, Val loss 1.544\n",
      "Ep 2 (Step 013460): Train loss 0.975, Val loss 1.542\n",
      "Ep 2 (Step 013465): Train loss 1.234, Val loss 1.540\n",
      "Ep 2 (Step 013470): Train loss 1.264, Val loss 1.540\n",
      "Ep 2 (Step 013475): Train loss 1.112, Val loss 1.541\n",
      "Ep 2 (Step 013480): Train loss 1.329, Val loss 1.541\n",
      "Ep 2 (Step 013485): Train loss 1.254, Val loss 1.542\n",
      "Ep 2 (Step 013490): Train loss 1.013, Val loss 1.543\n",
      "Ep 2 (Step 013495): Train loss 1.225, Val loss 1.544\n",
      "Ep 2 (Step 013500): Train loss 1.176, Val loss 1.546\n",
      "Ep 2 (Step 013505): Train loss 1.352, Val loss 1.547\n",
      "Ep 2 (Step 013510): Train loss 1.317, Val loss 1.546\n",
      "Ep 2 (Step 013515): Train loss 1.184, Val loss 1.546\n",
      "Ep 2 (Step 013520): Train loss 1.314, Val loss 1.546\n",
      "Ep 2 (Step 013525): Train loss 1.319, Val loss 1.545\n",
      "Ep 2 (Step 013530): Train loss 1.322, Val loss 1.545\n",
      "Ep 2 (Step 013535): Train loss 1.155, Val loss 1.546\n",
      "Ep 2 (Step 013540): Train loss 1.146, Val loss 1.547\n",
      "Ep 2 (Step 013545): Train loss 1.130, Val loss 1.546\n",
      "Ep 2 (Step 013550): Train loss 1.294, Val loss 1.544\n",
      "Ep 2 (Step 013555): Train loss 1.231, Val loss 1.542\n",
      "Ep 2 (Step 013560): Train loss 1.184, Val loss 1.541\n",
      "Ep 2 (Step 013565): Train loss 1.194, Val loss 1.541\n",
      "Ep 2 (Step 013570): Train loss 1.269, Val loss 1.540\n",
      "Ep 2 (Step 013575): Train loss 1.215, Val loss 1.541\n",
      "Ep 2 (Step 013580): Train loss 1.081, Val loss 1.539\n",
      "Ep 2 (Step 013585): Train loss 1.294, Val loss 1.540\n",
      "Ep 2 (Step 013590): Train loss 1.248, Val loss 1.541\n",
      "Ep 2 (Step 013595): Train loss 1.230, Val loss 1.541\n",
      "Ep 2 (Step 013600): Train loss 1.365, Val loss 1.541\n",
      "Ep 2 (Step 013605): Train loss 1.331, Val loss 1.541\n",
      "Ep 2 (Step 013610): Train loss 1.071, Val loss 1.542\n",
      "Ep 2 (Step 013615): Train loss 1.308, Val loss 1.543\n",
      "Ep 2 (Step 013620): Train loss 1.230, Val loss 1.544\n",
      "Ep 2 (Step 013625): Train loss 1.133, Val loss 1.545\n",
      "Ep 2 (Step 013630): Train loss 1.385, Val loss 1.545\n",
      "Ep 2 (Step 013635): Train loss 1.328, Val loss 1.545\n",
      "Ep 2 (Step 013640): Train loss 1.132, Val loss 1.545\n",
      "Ep 2 (Step 013645): Train loss 1.221, Val loss 1.545\n",
      "Ep 2 (Step 013650): Train loss 1.383, Val loss 1.544\n",
      "Ep 2 (Step 013655): Train loss 1.065, Val loss 1.543\n",
      "Ep 2 (Step 013660): Train loss 1.338, Val loss 1.544\n",
      "Ep 2 (Step 013665): Train loss 1.286, Val loss 1.544\n",
      "Ep 2 (Step 013670): Train loss 1.236, Val loss 1.541\n",
      "Ep 2 (Step 013675): Train loss 1.288, Val loss 1.539\n",
      "Ep 2 (Step 013680): Train loss 1.306, Val loss 1.539\n",
      "Ep 2 (Step 013685): Train loss 1.297, Val loss 1.541\n",
      "Ep 2 (Step 013690): Train loss 1.241, Val loss 1.544\n",
      "Ep 2 (Step 013695): Train loss 1.301, Val loss 1.547\n",
      "Ep 2 (Step 013700): Train loss 1.210, Val loss 1.548\n",
      "Ep 2 (Step 013705): Train loss 1.126, Val loss 1.549\n",
      "Ep 2 (Step 013710): Train loss 1.261, Val loss 1.550\n",
      "Ep 2 (Step 013715): Train loss 1.050, Val loss 1.550\n",
      "Ep 2 (Step 013720): Train loss 1.273, Val loss 1.549\n",
      "Ep 2 (Step 013725): Train loss 1.188, Val loss 1.548\n",
      "Ep 2 (Step 013730): Train loss 1.180, Val loss 1.546\n",
      "Ep 2 (Step 013735): Train loss 1.285, Val loss 1.546\n",
      "Ep 2 (Step 013740): Train loss 1.236, Val loss 1.545\n",
      "Ep 2 (Step 013745): Train loss 1.204, Val loss 1.546\n",
      "Ep 2 (Step 013750): Train loss 1.218, Val loss 1.548\n",
      "Ep 2 (Step 013755): Train loss 1.121, Val loss 1.548\n",
      "Ep 2 (Step 013760): Train loss 1.302, Val loss 1.546\n",
      "Ep 2 (Step 013765): Train loss 1.192, Val loss 1.543\n",
      "Ep 2 (Step 013770): Train loss 1.138, Val loss 1.542\n",
      "Ep 2 (Step 013775): Train loss 1.105, Val loss 1.542\n",
      "Ep 2 (Step 013780): Train loss 1.179, Val loss 1.541\n",
      "Ep 2 (Step 013785): Train loss 1.129, Val loss 1.541\n",
      "Ep 2 (Step 013790): Train loss 1.131, Val loss 1.541\n",
      "Ep 2 (Step 013795): Train loss 1.008, Val loss 1.544\n",
      "Ep 2 (Step 013800): Train loss 1.235, Val loss 1.545\n",
      "Ep 2 (Step 013805): Train loss 1.093, Val loss 1.547\n",
      "Ep 2 (Step 013810): Train loss 1.092, Val loss 1.549\n",
      "Ep 2 (Step 013815): Train loss 1.271, Val loss 1.550\n",
      "Ep 2 (Step 013820): Train loss 1.179, Val loss 1.550\n",
      "Ep 2 (Step 013825): Train loss 1.074, Val loss 1.548\n",
      "Ep 2 (Step 013830): Train loss 1.261, Val loss 1.546\n",
      "Ep 2 (Step 013835): Train loss 1.240, Val loss 1.543\n",
      "Ep 2 (Step 013840): Train loss 1.322, Val loss 1.542\n",
      "Ep 2 (Step 013845): Train loss 1.219, Val loss 1.541\n",
      "Ep 2 (Step 013850): Train loss 1.232, Val loss 1.541\n",
      "Ep 2 (Step 013855): Train loss 1.142, Val loss 1.542\n",
      "Ep 2 (Step 013860): Train loss 1.404, Val loss 1.541\n",
      "Ep 2 (Step 013865): Train loss 1.050, Val loss 1.541\n",
      "Ep 2 (Step 013870): Train loss 1.251, Val loss 1.542\n",
      "Ep 2 (Step 013875): Train loss 1.324, Val loss 1.544\n",
      "Ep 2 (Step 013880): Train loss 1.250, Val loss 1.546\n",
      "Ep 2 (Step 013885): Train loss 1.312, Val loss 1.546\n",
      "Ep 2 (Step 013890): Train loss 1.289, Val loss 1.546\n",
      "Ep 2 (Step 013895): Train loss 1.148, Val loss 1.545\n",
      "Ep 2 (Step 013900): Train loss 1.241, Val loss 1.546\n",
      "Ep 2 (Step 013905): Train loss 1.173, Val loss 1.545\n",
      "Ep 2 (Step 013910): Train loss 1.451, Val loss 1.543\n",
      "Ep 2 (Step 013915): Train loss 1.257, Val loss 1.543\n",
      "Ep 2 (Step 013920): Train loss 1.265, Val loss 1.543\n",
      "Ep 2 (Step 013925): Train loss 1.157, Val loss 1.542\n",
      "Ep 2 (Step 013930): Train loss 1.048, Val loss 1.543\n",
      "Ep 2 (Step 013935): Train loss 1.176, Val loss 1.545\n",
      "Ep 2 (Step 013940): Train loss 1.144, Val loss 1.545\n",
      "Ep 2 (Step 013945): Train loss 1.324, Val loss 1.545\n",
      "Ep 2 (Step 013950): Train loss 1.118, Val loss 1.544\n",
      "Ep 2 (Step 013955): Train loss 1.140, Val loss 1.541\n",
      "Ep 2 (Step 013960): Train loss 1.214, Val loss 1.539\n",
      "Ep 2 (Step 013965): Train loss 1.241, Val loss 1.537\n",
      "Ep 2 (Step 013970): Train loss 1.192, Val loss 1.536\n",
      "Ep 2 (Step 013975): Train loss 1.106, Val loss 1.534\n",
      "Ep 2 (Step 013980): Train loss 1.077, Val loss 1.535\n",
      "Ep 2 (Step 013985): Train loss 1.255, Val loss 1.535\n",
      "Ep 2 (Step 013990): Train loss 1.209, Val loss 1.534\n",
      "Ep 2 (Step 013995): Train loss 1.236, Val loss 1.534\n",
      "Ep 2 (Step 014000): Train loss 1.247, Val loss 1.534\n",
      "Checkpoint saved: checkpoints/ckpt_step14000.pt\n",
      "Removed old checkpoint: checkpoints/ckpt_step12000.pt\n",
      "Ep 2 (Step 014005): Train loss 1.119, Val loss 1.535\n",
      "Ep 2 (Step 014010): Train loss 1.341, Val loss 1.535\n",
      "Ep 2 (Step 014015): Train loss 1.119, Val loss 1.536\n",
      "Ep 2 (Step 014020): Train loss 1.117, Val loss 1.536\n",
      "Ep 2 (Step 014025): Train loss 1.201, Val loss 1.538\n",
      "Ep 2 (Step 014030): Train loss 1.360, Val loss 1.540\n",
      "Ep 2 (Step 014035): Train loss 1.086, Val loss 1.542\n",
      "Ep 2 (Step 014040): Train loss 1.166, Val loss 1.545\n",
      "Ep 2 (Step 014045): Train loss 1.204, Val loss 1.543\n",
      "Ep 2 (Step 014050): Train loss 1.221, Val loss 1.543\n",
      "Ep 2 (Step 014055): Train loss 1.198, Val loss 1.543\n",
      "Ep 2 (Step 014060): Train loss 1.226, Val loss 1.543\n",
      "Ep 2 (Step 014065): Train loss 1.197, Val loss 1.543\n",
      "Ep 2 (Step 014070): Train loss 1.335, Val loss 1.540\n",
      "Ep 2 (Step 014075): Train loss 1.230, Val loss 1.539\n",
      "Ep 2 (Step 014080): Train loss 1.174, Val loss 1.539\n",
      "Ep 2 (Step 014085): Train loss 1.201, Val loss 1.538\n",
      "Ep 2 (Step 014090): Train loss 1.286, Val loss 1.536\n",
      "Ep 2 (Step 014095): Train loss 1.218, Val loss 1.532\n",
      "Ep 2 (Step 014100): Train loss 1.108, Val loss 1.532\n",
      "Ep 2 (Step 014105): Train loss 1.245, Val loss 1.534\n",
      "Ep 2 (Step 014110): Train loss 1.235, Val loss 1.537\n",
      "Ep 2 (Step 014115): Train loss 1.301, Val loss 1.541\n",
      "Ep 2 (Step 014120): Train loss 1.192, Val loss 1.543\n",
      "Ep 2 (Step 014125): Train loss 1.300, Val loss 1.544\n",
      "Ep 2 (Step 014130): Train loss 1.267, Val loss 1.544\n",
      "Ep 2 (Step 014135): Train loss 1.181, Val loss 1.542\n",
      "Ep 2 (Step 014140): Train loss 1.238, Val loss 1.540\n",
      "Ep 2 (Step 014145): Train loss 1.208, Val loss 1.541\n",
      "Ep 2 (Step 014150): Train loss 1.138, Val loss 1.544\n",
      "Ep 2 (Step 014155): Train loss 1.178, Val loss 1.548\n",
      "Ep 2 (Step 014160): Train loss 1.259, Val loss 1.550\n",
      "Ep 2 (Step 014165): Train loss 1.208, Val loss 1.549\n",
      "Ep 2 (Step 014170): Train loss 1.180, Val loss 1.548\n",
      "Ep 2 (Step 014175): Train loss 1.184, Val loss 1.545\n",
      "Ep 2 (Step 014180): Train loss 1.103, Val loss 1.542\n",
      "Ep 2 (Step 014185): Train loss 1.195, Val loss 1.542\n",
      "Ep 2 (Step 014190): Train loss 1.175, Val loss 1.544\n",
      "Ep 2 (Step 014195): Train loss 1.018, Val loss 1.544\n",
      "Ep 2 (Step 014200): Train loss 1.413, Val loss 1.547\n",
      "Ep 2 (Step 014205): Train loss 1.354, Val loss 1.550\n",
      "Ep 2 (Step 014210): Train loss 1.078, Val loss 1.554\n",
      "Ep 2 (Step 014215): Train loss 1.242, Val loss 1.556\n",
      "Ep 2 (Step 014220): Train loss 1.186, Val loss 1.557\n",
      "Ep 2 (Step 014225): Train loss 1.260, Val loss 1.555\n",
      "Ep 2 (Step 014230): Train loss 1.280, Val loss 1.553\n",
      "Ep 2 (Step 014235): Train loss 1.220, Val loss 1.551\n",
      "Ep 2 (Step 014240): Train loss 1.122, Val loss 1.550\n",
      "Ep 2 (Step 014245): Train loss 1.182, Val loss 1.550\n",
      "Ep 2 (Step 014250): Train loss 1.245, Val loss 1.550\n",
      "Ep 2 (Step 014255): Train loss 1.093, Val loss 1.550\n",
      "Ep 2 (Step 014260): Train loss 1.231, Val loss 1.551\n",
      "Ep 2 (Step 014265): Train loss 1.275, Val loss 1.553\n",
      "Ep 2 (Step 014270): Train loss 1.151, Val loss 1.553\n",
      "Ep 2 (Step 014275): Train loss 1.300, Val loss 1.553\n",
      "Ep 2 (Step 014280): Train loss 1.241, Val loss 1.556\n",
      "Ep 2 (Step 014285): Train loss 1.290, Val loss 1.559\n",
      "Ep 2 (Step 014290): Train loss 1.247, Val loss 1.561\n",
      "Ep 2 (Step 014295): Train loss 1.124, Val loss 1.561\n",
      "Ep 2 (Step 014300): Train loss 1.196, Val loss 1.560\n",
      "Ep 2 (Step 014305): Train loss 1.269, Val loss 1.558\n",
      "Ep 2 (Step 014310): Train loss 1.153, Val loss 1.556\n",
      "Ep 2 (Step 014315): Train loss 1.166, Val loss 1.553\n",
      "Ep 2 (Step 014320): Train loss 1.105, Val loss 1.552\n",
      "Ep 2 (Step 014325): Train loss 1.171, Val loss 1.551\n",
      "Ep 2 (Step 014330): Train loss 1.207, Val loss 1.551\n",
      "Ep 2 (Step 014335): Train loss 1.248, Val loss 1.551\n",
      "Ep 2 (Step 014340): Train loss 1.233, Val loss 1.553\n",
      "Ep 2 (Step 014345): Train loss 1.283, Val loss 1.556\n",
      "Ep 2 (Step 014350): Train loss 1.263, Val loss 1.557\n",
      "Ep 2 (Step 014355): Train loss 1.163, Val loss 1.557\n",
      "Ep 2 (Step 014360): Train loss 1.120, Val loss 1.554\n",
      "Ep 2 (Step 014365): Train loss 1.292, Val loss 1.553\n",
      "Ep 2 (Step 014370): Train loss 1.321, Val loss 1.554\n",
      "Ep 2 (Step 014375): Train loss 1.145, Val loss 1.555\n",
      "Ep 2 (Step 014380): Train loss 1.242, Val loss 1.557\n",
      "Ep 2 (Step 014385): Train loss 1.207, Val loss 1.559\n",
      "Ep 2 (Step 014390): Train loss 1.273, Val loss 1.559\n",
      "Ep 2 (Step 014395): Train loss 1.348, Val loss 1.558\n",
      "Ep 2 (Step 014400): Train loss 1.173, Val loss 1.557\n",
      "Ep 2 (Step 014405): Train loss 1.230, Val loss 1.556\n",
      "Ep 2 (Step 014410): Train loss 1.271, Val loss 1.557\n",
      "Ep 2 (Step 014415): Train loss 1.256, Val loss 1.558\n",
      "Ep 2 (Step 014420): Train loss 1.188, Val loss 1.557\n",
      "Ep 2 (Step 014425): Train loss 1.278, Val loss 1.555\n",
      "Ep 2 (Step 014430): Train loss 1.335, Val loss 1.554\n",
      "Ep 2 (Step 014435): Train loss 1.280, Val loss 1.555\n",
      "Ep 2 (Step 014440): Train loss 1.229, Val loss 1.554\n",
      "Ep 2 (Step 014445): Train loss 1.202, Val loss 1.554\n",
      "Ep 2 (Step 014450): Train loss 1.282, Val loss 1.554\n",
      "Ep 2 (Step 014455): Train loss 1.322, Val loss 1.554\n",
      "Ep 2 (Step 014460): Train loss 1.200, Val loss 1.555\n",
      "Ep 2 (Step 014465): Train loss 1.153, Val loss 1.555\n",
      "Ep 2 (Step 014470): Train loss 1.151, Val loss 1.556\n",
      "Ep 2 (Step 014475): Train loss 1.185, Val loss 1.558\n",
      "Ep 2 (Step 014480): Train loss 1.341, Val loss 1.558\n",
      "Ep 2 (Step 014485): Train loss 1.230, Val loss 1.558\n",
      "CUDA OOM encountered. Saving checkpoint to checkpoints/oom_step14488.pt\n",
      "Returning partial metrics after OOM. Consider reducing batch size or sequence length.\n",
      "Training completed in 23.01 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00002, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_with_checkpoints(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer,\n",
    "    checkpoint_dir=\"checkpoints\",  # Directory to save checkpoints\n",
    "    checkpoint_freq_steps=1000,     # Save checkpoint every 1000 steps\n",
    "    keep_last_k=2,                  # Keep only the last 3 checkpoints\n",
    "    auto_resume=True                # Automatically resume from latest checkpoint if available\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3584ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-large774M-sft3.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft3.pth\"      #1\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d9062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e50c7dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fdb737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available 10K checkpoints: ['oom_step10299.pt', 'ckpt_step1000.pt', 'ckpt_step10000.pt']\n",
      "Loaded from step: 10000\n",
      "Epoch: 0\n",
      "✅ Best model loaded from Step 10K (Epoch 1)\n"
     ]
    }
   ],
   "source": [
    "# Find your exact checkpoint file\n",
    "import os\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "checkpoints = [f for f in os.listdir(checkpoint_dir) if '10' in f]\n",
    "print(\"Available 10K checkpoints:\", checkpoints)\n",
    "\n",
    "# Load the checkpoint (adjust filename based on what you find)\n",
    "checkpoint_path = \"checkpoints/ckpt_step10000.pt\"  # or oom_step10299.pt\n",
    "\n",
    "# Create model with same config\n",
    "model_best = GPTModel(BASE_CONFIG)\n",
    "for param in model_best.parameters():\n",
    "    param.requires_grad = False\n",
    "replace_linear_with_lora(model_best, rank=8, alpha=16)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "# The checkpoint might have full state or just model_state_dict\n",
    "if \"model_state_dict\" in checkpoint:\n",
    "    model_best.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(f\"Loaded from step: {checkpoint.get('global_step', 'unknown')}\")\n",
    "    print(f\"Epoch: {checkpoint.get('epoch', 'unknown')}\")\n",
    "else:\n",
    "    model_best.load_state_dict(checkpoint)\n",
    "\n",
    "model_best = model_best.to(device)\n",
    "model_best.eval()\n",
    "\n",
    "print(\"✅ Best model loaded from Step 10K (Epoch 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d91c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.191306734085083\n",
      "Validation loss: 1.5327175378799438\n",
      "Test loss: 1.2895723462104798\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model_best, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model_best, device, num_batches=5\n",
    "    )\n",
    "    test_loss = calc_loss_loader(\n",
    "        test_loader, model_best, device, num_batches=5\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a42d1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name a famous movie with the input name\n",
      "### Input:\n",
      "Grace\n",
      "### Response:\n",
      "\n",
      "\n",
      "Correct response:\n",
      ">> Grace Unplugged (2013)\n",
      "\n",
      "Model response:\n",
      ">> The Godfather\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:1]:      #1\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(               #2\n",
    "        model=model_best,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4308e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved as: gpt2-large774M-sft-BEST.pth\n",
      "   From: Step ~10K, End of Epoch 1\n",
      "   Val loss: ~1.54 (vs original 1.728)\n",
      "   Improvement: ~11% better generalization\n"
     ]
    }
   ],
   "source": [
    "# Save as your final production model\n",
    "final_model_name = \"gpt2-large774M-sft-BEST.pth\"\n",
    "torch.save(model_best.state_dict(), final_model_name)\n",
    "print(f\"✅ Best model saved as: {final_model_name}\")\n",
    "print(f\"   From: Step ~10K, End of Epoch 1\")\n",
    "print(f\"   Val loss: ~1.54 (vs original 1.728)\")\n",
    "print(f\"   Improvement: ~11% better generalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f069d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_random_test_records(test_data, num_records, seed, model, tokenizer, device, output_file=\"random_test_records.json\"):\n",
    "    \"\"\"\n",
    "    Selects random records from test_data, generates model responses, and saves them to a file \n",
    "    without modifying the original data.\n",
    "    \n",
    "    Args:\n",
    "        test_data (list): The test dataset to sample from\n",
    "        num_records (int): Number of random records to select\n",
    "        seed (int): Random seed for reproducible selection\n",
    "        model: The trained model for generating responses\n",
    "        tokenizer: Tokenizer for text processing\n",
    "        device: Device to run inference on\n",
    "        output_file (str): Output file path to save the selected records with model responses\n",
    "    \n",
    "    Returns:\n",
    "        list: The selected random records with model responses (copy of original data)\n",
    "    \"\"\"\n",
    "    # Set the random seed for reproducible results\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Create a deep copy to avoid modifying the original test_data\n",
    "    test_data_copy = deepcopy(test_data)\n",
    "    \n",
    "    # Ensure we don't try to select more records than available\n",
    "    num_records = min(num_records, len(test_data_copy))\n",
    "    \n",
    "    # Randomly sample records without replacement\n",
    "    selected_records = random.sample(test_data_copy, num_records)\n",
    "    \n",
    "    print(f\"Generating model responses for {len(selected_records)} selected records...\")\n",
    "    \n",
    "    # Generate model responses for each selected record\n",
    "    for i, entry in tqdm(enumerate(selected_records), total=len(selected_records)):\n",
    "        # Create formatted input text\n",
    "        input_text = format_input(entry)\n",
    "        \n",
    "        # Generate model response\n",
    "        token_ids = generate(\n",
    "            model=model,\n",
    "            idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "            max_new_tokens=256,\n",
    "            context_size=BASE_CONFIG[\"context_length\"],  # Using the context length from BASE_CONFIG\n",
    "            eos_id=50256\n",
    "        )\n",
    "        generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        \n",
    "        # Extract the model response (remove the input prompt)\n",
    "        response_text = (\n",
    "            generated_text[len(input_text):]\n",
    "            .replace(\"### Response:\", \"\")\n",
    "            .strip()\n",
    "        )\n",
    "        \n",
    "        # Add the model response to the entry\n",
    "        selected_records[i][\"model_response\"] = response_text\n",
    "        \n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(selected_records, file, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Successfully saved {len(selected_records)} random records with model responses to '{output_file}'\")\n",
    "    print(f\"Used seed: {seed}\")\n",
    "    \n",
    "    return selected_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58fb714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating model responses for 50 selected records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:20<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 50 random records with model responses to 'my_random_test_with_responses.json'\n",
      "Used seed: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_records = save_random_test_records(\n",
    "    test_data, \n",
    "    num_records=50, \n",
    "    seed=42, \n",
    "    model=model_best, \n",
    "    tokenizer=tokenizer, \n",
    "    device=device, \n",
    "    output_file=\"my_random_test_with_responses.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7b66c",
   "metadata": {},
   "source": [
    "# 🚀 Improved Training Configuration\n",
    "\n",
    "## Changes to Prevent Overfitting:\n",
    "\n",
    "### ✅ Already Applied:\n",
    "1. **Dropout enabled**: `drop_rate = 0.1` (prevents memorization)\n",
    "\n",
    "### 🆕 New Improvements:\n",
    "2. **Lower learning rate**: `5e-5 → 2e-5` (better generalization)\n",
    "3. **Reduced weight decay**: `0.1 → 0.01` (less aggressive regularization)\n",
    "4. **Gradient clipping**: `max_norm=1.0` (training stability)\n",
    "5. **Learning rate scheduler**: Cosine annealing (gradual LR reduction)\n",
    "6. **Early stopping**: Stop when validation loss plateaus\n",
    "7. **Increased batch size**: `4 → 8` (more stable gradients, if GPU memory allows)\n",
    "\n",
    "### Optional:\n",
    "8. **Reduced LoRA rank**: `16 → 8` (less overfitting capacity)\n",
    "\n",
    "---\n",
    "\n",
    "## Why These Changes Help:\n",
    "\n",
    "**Current Problem:** Training loss (1.008) << Validation loss (1.728) = **Overfitting**\n",
    "\n",
    "**Solution:** These changes force the model to learn generalizable patterns instead of memorizing training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# IMPROVED TRAINING CONFIGURATION\n",
    "# ========================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🔧 IMPROVED TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Hyperparameters comparison\n",
    "config_comparison = {\n",
    "    \"Learning Rate\": {\"Old\": \"5e-5\", \"New\": \"2e-5\", \"Reason\": \"Better generalization\"},\n",
    "    \"Weight Decay\": {\"Old\": \"0.1\", \"New\": \"0.01\", \"Reason\": \"Less aggressive regularization\"},\n",
    "    \"Batch Size\": {\"Old\": \"4\", \"New\": \"8\", \"Reason\": \"More stable gradients\"},\n",
    "    \"Dropout\": {\"Old\": \"0.0\", \"New\": \"0.1\", \"Reason\": \"Already enabled ✓\"},\n",
    "    \"Gradient Clip\": {\"Old\": \"None\", \"New\": \"1.0\", \"Reason\": \"Training stability\"},\n",
    "    \"LR Scheduler\": {\"Old\": \"None\", \"New\": \"Cosine\", \"Reason\": \"Gradual LR reduction\"},\n",
    "    \"Early Stopping\": {\"Old\": \"None\", \"New\": \"3 epochs\", \"Reason\": \"Auto-optimization\"},\n",
    "}\n",
    "\n",
    "for param, values in config_comparison.items():\n",
    "    print(f\"\\n{param:15s}: {values['Old']:8s} → {values['New']:10s}\")\n",
    "    print(f\"                └─ {values['Reason']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354de5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
